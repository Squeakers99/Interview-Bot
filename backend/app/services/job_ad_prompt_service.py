import json
import os
import re
from typing import Any

from dotenv import load_dotenv
from openai import OpenAI

from app.services.prompt_store import normalize_difficulty, normalize_prompt_type

load_dotenv()

XAI_BASE_URL = os.getenv("XAI_BASE_URL", "https://api.x.ai/v1")
XAI_MODEL = os.getenv("XAI_MODEL", "grok-4-fast-non-reasoning")


def _xai_client() -> OpenAI:
    api_key = os.getenv("GROQ_API_KEY")
    if not api_key:
        raise ValueError("Missing XAI_API_KEY (or GROK_API_KEY) for Grok prompt generation.")
    return OpenAI(api_key=api_key, base_url=XAI_BASE_URL)


def _extract_json_object(raw_text: str) -> dict[str, Any]:
    text = (raw_text or "").strip()
    if not text:
        raise ValueError("Empty Grok response while generating job-ad prompt.")

    try:
        parsed = json.loads(text)
        if isinstance(parsed, dict):
            return parsed
    except json.JSONDecodeError:
        pass

    fenced_match = re.search(r"```(?:json)?\s*(\{.*\})\s*```", text, flags=re.DOTALL | re.IGNORECASE)
    if fenced_match:
        parsed = json.loads(fenced_match.group(1))
        if isinstance(parsed, dict):
            return parsed

    first = text.find("{")
    last = text.rfind("}")
    if first != -1 and last != -1 and last > first:
        parsed = json.loads(text[first : last + 1])
        if isinstance(parsed, dict):
            return parsed

    raise ValueError("Could not parse JSON object from Grok response.")


def _coerce_string_list(value: Any, fallback: list[str]) -> list[str]:
    if not isinstance(value, list):
        return fallback
    cleaned = [str(item).strip() for item in value if str(item).strip()]
    return cleaned[:5] or fallback


def generate_prompt_from_job_ad_with_grok(
    *,
    job_url: str,
    job_title: str,
    job_text: str,
    prompt_type: str = "all",
    difficulty: str = "all",
) -> dict[str, Any]:
    normalized_type = normalize_prompt_type(prompt_type)
    normalized_difficulty = normalize_difficulty(difficulty)

    system_prompt = (
        "You generate one high-quality interview practice question from a job advertisement. "
        "Return strict JSON only, no markdown. Keep the question realistic and role-specific."
    )

    user_prompt = f"""
Generate one interview prompt from this job ad.

Requirements:
- Use the job ad details heavily (responsibilities, skills, seniority).
- If prompt_type is not "all", use it exactly.
- If difficulty is not "all", use it exactly.
- If prompt_type is "all", infer one of: technical, behavioral, situational, general.
- If difficulty is "all", infer one of: easy, medium, hard, expert, master.
- Return a JSON with the following type signature (Everything following a hashtag is an explanation and should not be included in the output):
    "id": "custom_prompt", # this is just an ID for the prompt, can be anything unique]
    "type": "HERE",  # one of: technical, behavioral, situational, general; as entered by the user
    "text": "HERE",  # the interview question prompt text
    "difficulty": "HERE", # one of: easy, medium, hard, expert, master; as entered by the user
    "good_signals": ["HERE_1","HERE_2",...], # up to 5 items; what would make this a good answer to the prompt? (specific to the prompt and ideally tied to the job ad details)
    "red_flags": ["HERE_1","HERE_2",...], # up to 5 items; what would make this a bad answer to the prompt? (specific to the prompt and ideally tied to the job ad details)  

User-selected filters:
- prompt_type: {normalized_type}
- difficulty: {normalized_difficulty}

Job Ad URL:
{job_url}

Job Ad Title:
{job_title}

Job Ad Text (truncated):
{job_text[:10000]}
""".strip()

    client = _xai_client()
    response = client.chat.completions.create(
        model=XAI_MODEL,
        messages=[
            {"role": "system", "content": system_prompt},
            {"role": "user", "content": user_prompt},
        ],
        temperature=0.4,
    )

    content = response.choices[0].message.content if response.choices else ""
    payload = _extract_json_object(content or "")

    result_type = normalize_prompt_type(str(payload.get("type", normalized_type)))
    if normalized_type != "all":
        result_type = normalized_type
    if result_type == "all":
        result_type = "technical"

    result_difficulty = normalize_difficulty(str(payload.get("difficulty", normalized_difficulty)))
    if normalized_difficulty != "all":
        result_difficulty = normalized_difficulty
    if result_difficulty == "all":
        result_difficulty = "medium"

    question_text = str(payload.get("text", "")).strip()
    if not question_text:
        raise ValueError("Grok response did not include prompt text.")
    
    # Prints the Prompt generated by Grok for debugging purposes
    print("Generated prompt from Grok:", {
        "type": result_type,
        "difficulty": result_difficulty,
        "text": question_text,
        "good_signals": _coerce_string_list(payload.get("good_signals"), []
        ),
        "red_flags": _coerce_string_list(payload.get("red_flags"), []
        ), "job_ad_url": job_url,
        "job_ad_title": job_title,
    })
    
    return {
        "id": f"jobad_grok_{abs(hash((job_url, job_title, question_text))) % 10_000_000}",
        "type": result_type,
        "difficulty": result_difficulty,
        "text": question_text,
        "good_signals": _coerce_string_list(
            payload.get("good_signals"),
            [
                "References responsibilities and requirements from the job ad",
                "Explains tradeoffs and decisions clearly",
            ],
        ),
        "red_flags": _coerce_string_list(
            payload.get("red_flags"),
            [
                "Generic answer not tied to the posted role",
                "No clear rationale or prioritization",
            ],
        ),
        "job_ad_url": job_url,
        "job_ad_title": job_title,
    }